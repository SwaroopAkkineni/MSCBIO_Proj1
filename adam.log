2016-10-02 22:07:20 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1." "phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:08:02 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1." "phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:10:14 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:10:14 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:10:14 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:10:15 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:10:15 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:10:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:10:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:10:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:10:15 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 62906.
2016-10-02 22:10:15 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:10:15 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:10:15 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-4c5eacd1-6536-4448-95b6-313fef9633e8
2016-10-02 22:10:16 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:10:16 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:10:16 INFO  log:186 - Logging initialized @2946ms
2016-10-02 22:10:16 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:10:16 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:10:16 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6e46d9f4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:10:16 INFO  ServerConnector:306 - Stopped ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:10:16 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-02 22:10:16 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:10:16 INFO  ServerConnector:266 - Started ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:10:16 INFO  Server:379 - Started @3181ms
2016-10-02 22:10:16 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-02 22:10:16 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4041
2016-10-02 22:10:16 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:62906/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475460616525
2016-10-02 22:10:16 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:10:16 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62909.
2016-10-02 22:10:16 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:62909
2016-10-02 22:10:16 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 62909)
2016-10-02 22:10:16 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:62909 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 62909)
2016-10-02 22:10:16 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 62909)
2016-10-02 22:10:16 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d81e101{/metrics/json,null,AVAILABLE}
2016-10-02 22:10:17 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:10:18 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:10:18 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:62909 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:10:18 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:10:19 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:10:19 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:10:19 INFO  FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2016-10-02 22:10:19 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-02 22:10:19 INFO  SparkContext:54 - Starting job: saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130
2016-10-02 22:10:19 INFO  DAGScheduler:54 - Got job 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130) with 1 output partitions
2016-10-02 22:10:19 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130)
2016-10-02 22:10:19 INFO  DAGScheduler:54 - Parents of final stage: List()
2016-10-02 22:10:19 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-02 22:10:19 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at map at ADAMRDDFunctions.scala:128), which has no missing parents
2016-10-02 22:10:19 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 90.6 KB, free 365.9 MB)
2016-10-02 22:10:19 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.0 KB, free 365.9 MB)
2016-10-02 22:10:19 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.0.3:62909 (size: 34.0 KB, free: 366.2 MB)
2016-10-02 22:10:19 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-02 22:10:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at ADAMRDDFunctions.scala:128)
2016-10-02 22:10:19 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-02 22:10:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5629 bytes)
2016-10-02 22:10:19 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-02 22:10:19 INFO  Executor:54 - Fetching spark://10.0.0.3:62906/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475460616525
2016-10-02 22:10:19 INFO  TransportClientFactory:250 - Successfully created connection to /10.0.0.3:62906 after 52 ms (0 ms spent in bootstraps)
2016-10-02 22:10:19 INFO  Utils:54 - Fetching spark://10.0.0.3:62906/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-3b69b395-7dfa-4303-be47-6b94f1be6330/userFiles-05675968-afd7-4414-922d-ef798ad19fe8/fetchFileTemp1126489375387104136.tmp
2016-10-02 22:10:20 INFO  Executor:54 - Adding file:/private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-3b69b395-7dfa-4303-be47-6b94f1be6330/userFiles-05675968-afd7-4414-922d-ef798ad19fe8/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-02 22:10:20 INFO  NewHadoopRDD:54 - Input split: file:/Users/swaroopakkineni/Desktop/Fall Semester 2016/Scalable ML/project1/1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz:0+95523
2016-10-02 22:10:20 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:10:20 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:10:20 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:10:20 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:10:20 INFO  FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2016-10-02 22:10:20 INFO  CodecPool:153 - Got brand-new compressor [.gz]
2016-10-02 22:10:33 INFO  FileOutputCommitter:482 - Saved output of task 'attempt_201610022210_0003_r_000000_0' to file:/Users/swaroopakkineni/Desktop/Fall Semester 2016/Scalable ML/project1/small.adam/_temporary/0/task_201610022210_0003_r_000000
2016-10-02 22:10:33 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1115 bytes result sent to driver
2016-10-02 22:10:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 13373 ms on localhost (1/1)
2016-10-02 22:10:33 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-02 22:10:33 INFO  DAGScheduler:54 - ResultStage 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130) finished in 13.402 s
2016-10-02 22:10:33 INFO  DAGScheduler:54 - Job 0 finished: saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130, took 13.673105 s
2016-10-02 22:10:33 INFO  Vcf2ADAM:44 - Overall Duration: 18.96 secs
2016-10-02 22:10:33 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:10:33 INFO  ServerConnector:306 - Stopped ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:10:33 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4041
2016-10-02 22:10:33 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:10:33 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:10:33 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:10:33 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:10:33 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:10:33 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:10:33 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:10:33 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-3b69b395-7dfa-4303-be47-6b94f1be6330
2016-10-02 22:17:26 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:17:26 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@760487aa{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:17:26 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@5995851e: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:17:26 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-02 22:17:27 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-02 22:17:35 INFO  ADAMMain:115 - ADAM invoked with args: 
2016-10-02 22:18:32 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:18:32 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:18:33 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:18:33 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:18:33 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:18:33 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:18:33 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:18:33 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:18:33 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63070.
2016-10-02 22:18:33 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:18:33 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:18:33 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-a862de6f-dc66-4037-b8b1-d39a5e3a6ced
2016-10-02 22:18:33 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:18:33 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:18:33 INFO  log:186 - Logging initialized @1398ms
2016-10-02 22:18:33 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:18:33 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:18:33 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6e46d9f4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:18:33 INFO  ServerConnector:306 - Stopped ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:18:33 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-02 22:18:33 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:18:33 INFO  ServerConnector:266 - Started ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:18:33 INFO  Server:379 - Started @1521ms
2016-10-02 22:18:33 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-02 22:18:33 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4041
2016-10-02 22:18:33 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63070/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461113697
2016-10-02 22:18:33 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:18:33 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63071.
2016-10-02 22:18:33 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63071
2016-10-02 22:18:33 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63071)
2016-10-02 22:18:33 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63071 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63071)
2016-10-02 22:18:33 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63071)
2016-10-02 22:18:33 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d81e101{/metrics/json,null,AVAILABLE}
2016-10-02 22:18:34 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:18:34 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:18:34 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63071 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:18:34 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:18:34 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:18:34 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:18:34 INFO  Vcf2ADAM:44 - Overall Duration: 2.21 secs
2016-10-02 22:18:34 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:18:34 INFO  ServerConnector:306 - Stopped ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:18:34 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4041
2016-10-02 22:18:34 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:18:34 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:18:34 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:18:34 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:18:34 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:18:34 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:18:34 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:18:34 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-09c909ec-3d07-4a67-8452-773c25bd1487
2016-10-02 22:19:21 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:19:21 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:19:21 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:19:21 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:19:21 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:19:21 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:19:21 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:19:21 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:19:21 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63077.
2016-10-02 22:19:21 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:19:21 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:19:21 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-0693b24e-f668-4090-bb93-4f1fbf1c47aa
2016-10-02 22:19:21 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:19:22 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:19:22 INFO  log:186 - Logging initialized @1497ms
2016-10-02 22:19:22 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:19:22 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:19:22 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6e46d9f4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:19:22 INFO  ServerConnector:306 - Stopped ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:19:22 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-02 22:19:22 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:19:22 INFO  ServerConnector:266 - Started ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:19:22 INFO  Server:379 - Started @1642ms
2016-10-02 22:19:22 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-02 22:19:22 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4041
2016-10-02 22:19:22 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63077/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461162266
2016-10-02 22:19:22 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:19:22 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63078.
2016-10-02 22:19:22 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63078
2016-10-02 22:19:22 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63078)
2016-10-02 22:19:22 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63078 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63078)
2016-10-02 22:19:22 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63078)
2016-10-02 22:19:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d81e101{/metrics/json,null,AVAILABLE}
2016-10-02 22:19:22 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:19:23 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:19:23 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63078 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:19:23 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:19:23 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:19:23 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:19:23 INFO  Vcf2ADAM:44 - Overall Duration: 2.43 secs
2016-10-02 22:19:23 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:19:23 INFO  ServerConnector:306 - Stopped ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:19:23 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4041
2016-10-02 22:19:23 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:19:23 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:19:23 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:19:23 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:19:23 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:19:23 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:19:23 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:19:23 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-159c4dc3-fd82-43cc-a0f0-4e8c4da79589
2016-10-02 22:19:39 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:19:39 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:19:39 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:19:39 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:19:39 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:19:39 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:19:39 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:19:39 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:19:40 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63091.
2016-10-02 22:19:40 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:19:40 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:19:40 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-15b52d01-2bed-4e1d-b2ff-412f27c98558
2016-10-02 22:19:40 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:19:40 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:19:40 INFO  log:186 - Logging initialized @1441ms
2016-10-02 22:19:40 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:19:40 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:19:40 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6e46d9f4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:19:40 INFO  ServerConnector:306 - Stopped ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:19:40 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-02 22:19:40 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:19:40 INFO  ServerConnector:266 - Started ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:19:40 INFO  Server:379 - Started @1567ms
2016-10-02 22:19:40 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-02 22:19:40 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4041
2016-10-02 22:19:40 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63091/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461180341
2016-10-02 22:19:40 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:19:40 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63092.
2016-10-02 22:19:40 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63092
2016-10-02 22:19:40 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63092)
2016-10-02 22:19:40 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63092 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63092)
2016-10-02 22:19:40 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63092)
2016-10-02 22:19:40 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d81e101{/metrics/json,null,AVAILABLE}
2016-10-02 22:19:40 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:19:41 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:19:41 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63092 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:19:41 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:19:41 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:19:41 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:19:41 INFO  Vcf2ADAM:44 - Overall Duration: 2.19 secs
2016-10-02 22:19:41 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:19:41 INFO  ServerConnector:306 - Stopped ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:19:41 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4041
2016-10-02 22:19:41 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:19:41 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:19:41 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:19:41 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:19:41 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:19:41 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:19:41 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:19:41 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-e6ed046c-1e14-48f7-bede-bc05e74a6c51
2016-10-02 22:19:45 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:19:45 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:19:45 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:19:45 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:19:45 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:19:45 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:19:45 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:19:45 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:19:46 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63093.
2016-10-02 22:19:46 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:19:46 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:19:46 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-560719e1-baa4-451e-8373-8d93368a8812
2016-10-02 22:19:46 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:19:46 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:19:46 INFO  log:186 - Logging initialized @1423ms
2016-10-02 22:19:46 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:19:46 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:19:46 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6e46d9f4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:19:46 INFO  ServerConnector:306 - Stopped ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:19:46 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-02 22:19:46 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:19:46 INFO  ServerConnector:266 - Started ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:19:46 INFO  Server:379 - Started @1545ms
2016-10-02 22:19:46 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-02 22:19:46 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4041
2016-10-02 22:19:46 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63093/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461186337
2016-10-02 22:19:46 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:19:46 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63094.
2016-10-02 22:19:46 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63094
2016-10-02 22:19:46 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63094)
2016-10-02 22:19:46 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63094 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63094)
2016-10-02 22:19:46 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63094)
2016-10-02 22:19:46 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d81e101{/metrics/json,null,AVAILABLE}
2016-10-02 22:19:46 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:19:47 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:19:47 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63094 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:19:47 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:19:47 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:19:47 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:19:47 INFO  Vcf2ADAM:44 - Overall Duration: 2.19 secs
2016-10-02 22:19:47 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:19:47 INFO  ServerConnector:306 - Stopped ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:19:47 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4041
2016-10-02 22:19:47 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:19:47 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:19:47 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:19:47 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:19:47 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:19:47 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:19:47 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:19:47 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-3b18b4cd-4e56-4637-a86d-08f7e0d8301a
2016-10-02 22:19:50 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:19:50 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:19:50 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:19:50 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:19:50 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:19:50 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:19:50 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:19:50 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:19:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63095.
2016-10-02 22:19:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:19:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:19:50 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-b1e18716-f02c-4504-aa8d-11b9f74890c0
2016-10-02 22:19:50 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:19:50 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:19:51 INFO  log:186 - Logging initialized @1377ms
2016-10-02 22:19:51 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:19:51 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:19:51 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6e46d9f4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:19:51 INFO  ServerConnector:306 - Stopped ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:19:51 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-02 22:19:51 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:19:51 INFO  ServerConnector:266 - Started ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:19:51 INFO  Server:379 - Started @1494ms
2016-10-02 22:19:51 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-02 22:19:51 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4041
2016-10-02 22:19:51 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63095/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461191156
2016-10-02 22:19:51 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:19:51 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63096.
2016-10-02 22:19:51 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63096
2016-10-02 22:19:51 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63096)
2016-10-02 22:19:51 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63096 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63096)
2016-10-02 22:19:51 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63096)
2016-10-02 22:19:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d81e101{/metrics/json,null,AVAILABLE}
2016-10-02 22:19:51 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:19:52 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:19:52 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63096 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:19:52 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:19:52 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:19:52 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:19:52 INFO  Vcf2ADAM:44 - Overall Duration: 2.06 secs
2016-10-02 22:19:52 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:19:52 INFO  ServerConnector:306 - Stopped ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:19:52 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4041
2016-10-02 22:19:52 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:19:52 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:19:52 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:19:52 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:19:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:19:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:19:52 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:19:52 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-bb11716c-238e-492f-965d-7982474d022f
2016-10-02 22:20:01 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:20:01 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:20:01 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:20:01 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:20:01 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:20:01 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:20:01 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:20:01 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:20:02 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63097.
2016-10-02 22:20:02 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:20:02 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:20:02 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-a8618b06-f9c1-48cc-b22c-81b04eabbe4e
2016-10-02 22:20:02 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:20:02 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:20:02 INFO  log:186 - Logging initialized @1392ms
2016-10-02 22:20:02 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:20:02 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:20:02 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6e46d9f4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.bdgenomics.utils.cli.BDGSparkCommand$class.run(BDGCommand.scala:52)
	at org.bdgenomics.adam.cli.Vcf2ADAM.run(Vcf2ADAM.scala:59)
	at org.bdgenomics.adam.cli.ADAMMain.apply(ADAMMain.scala:132)
	at org.bdgenomics.adam.cli.ADAMMain$.main(ADAMMain.scala:72)
	at org.bdgenomics.adam.cli.ADAMMain.main(ADAMMain.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-02 22:20:02 INFO  ServerConnector:306 - Stopped ServerConnector@1bdf8190{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:20:02 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-02 22:20:02 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:20:02 INFO  ServerConnector:266 - Started ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:20:02 INFO  Server:379 - Started @1514ms
2016-10-02 22:20:02 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-02 22:20:02 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4041
2016-10-02 22:20:02 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63097/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461202536
2016-10-02 22:20:02 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:20:02 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63098.
2016-10-02 22:20:02 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63098
2016-10-02 22:20:02 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63098)
2016-10-02 22:20:02 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63098 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63098)
2016-10-02 22:20:02 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63098)
2016-10-02 22:20:02 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d81e101{/metrics/json,null,AVAILABLE}
2016-10-02 22:20:03 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:20:03 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:20:03 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63098 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:20:03 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:20:03 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:20:03 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:20:03 INFO  Vcf2ADAM:44 - Overall Duration: 2.17 secs
2016-10-02 22:20:03 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:20:03 INFO  ServerConnector:306 - Stopped ServerConnector@372ea2bc{HTTP/1.1}{0.0.0.0:4041}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:20:03 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4041
2016-10-02 22:20:03 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:20:03 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:20:03 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:20:03 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:20:03 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:20:03 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:20:03 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:20:03 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-7cfed9ce-d391-4898-bd74-d6878ed8bcd2
2016-10-02 22:22:11 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:22:11 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:22:12 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:22:12 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:22:12 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:22:12 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:22:12 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:22:12 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:22:12 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63121.
2016-10-02 22:22:12 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:22:12 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:22:12 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-84d8820e-38d7-4309-ad09-871ef09924ad
2016-10-02 22:22:12 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:22:12 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:22:12 INFO  log:186 - Logging initialized @1637ms
2016-10-02 22:22:13 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:22:13 INFO  ServerConnector:266 - Started ServerConnector@460f76a6{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:22:13 INFO  Server:379 - Started @1738ms
2016-10-02 22:22:13 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-02 22:22:13 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4040
2016-10-02 22:22:13 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63121/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461333052
2016-10-02 22:22:13 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:22:13 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63122.
2016-10-02 22:22:13 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63122
2016-10-02 22:22:13 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63122)
2016-10-02 22:22:13 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63122 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63122)
2016-10-02 22:22:13 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63122)
2016-10-02 22:22:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@78d39a69{/metrics/json,null,AVAILABLE}
2016-10-02 22:22:13 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:22:13 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:22:13 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63122 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:22:13 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:22:14 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:22:14 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:22:14 INFO  Vcf2ADAM:44 - Overall Duration: 2.32 secs
2016-10-02 22:22:14 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:22:14 INFO  ServerConnector:306 - Stopped ServerConnector@460f76a6{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:22:14 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4040
2016-10-02 22:22:14 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:22:14 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:22:14 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:22:14 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:22:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:22:14 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:22:14 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:22:14 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-bd4653a7-84ad-40cd-9cc8-5b6dc4cd758f
2016-10-02 22:22:30 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "small.adam"
2016-10-02 22:22:30 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:22:30 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:22:31 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:22:31 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:22:31 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:22:31 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:22:31 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:22:31 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63123.
2016-10-02 22:22:31 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:22:31 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:22:31 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-85ba1dfd-c21e-4e77-803b-40206bd5c39f
2016-10-02 22:22:31 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:22:31 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:22:31 INFO  log:186 - Logging initialized @1370ms
2016-10-02 22:22:31 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:22:31 INFO  ServerConnector:266 - Started ServerConnector@460f76a6{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:22:31 INFO  Server:379 - Started @1469ms
2016-10-02 22:22:31 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-02 22:22:31 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4040
2016-10-02 22:22:31 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63123/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461351596
2016-10-02 22:22:31 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:22:31 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63124.
2016-10-02 22:22:31 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63124
2016-10-02 22:22:31 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63124)
2016-10-02 22:22:31 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63124 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63124)
2016-10-02 22:22:31 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63124)
2016-10-02 22:22:31 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@78d39a69{/metrics/json,null,AVAILABLE}
2016-10-02 22:22:32 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:22:32 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:22:32 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63124 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:22:32 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:22:32 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:22:32 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:22:32 INFO  FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2016-10-02 22:22:32 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-02 22:22:32 INFO  SparkContext:54 - Starting job: saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130
2016-10-02 22:22:32 INFO  DAGScheduler:54 - Got job 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130) with 1 output partitions
2016-10-02 22:22:32 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130)
2016-10-02 22:22:32 INFO  DAGScheduler:54 - Parents of final stage: List()
2016-10-02 22:22:32 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-02 22:22:32 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at map at ADAMRDDFunctions.scala:128), which has no missing parents
2016-10-02 22:22:32 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 90.6 KB, free 365.9 MB)
2016-10-02 22:22:32 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.0 KB, free 365.9 MB)
2016-10-02 22:22:32 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.0.3:63124 (size: 34.0 KB, free: 366.2 MB)
2016-10-02 22:22:32 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-02 22:22:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at ADAMRDDFunctions.scala:128)
2016-10-02 22:22:32 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-02 22:22:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5629 bytes)
2016-10-02 22:22:32 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-02 22:22:32 INFO  Executor:54 - Fetching spark://10.0.0.3:63123/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461351596
2016-10-02 22:22:32 INFO  TransportClientFactory:250 - Successfully created connection to /10.0.0.3:63123 after 22 ms (0 ms spent in bootstraps)
2016-10-02 22:22:32 INFO  Utils:54 - Fetching spark://10.0.0.3:63123/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-d80d605f-c87c-4d57-a991-27794844b0da/userFiles-22fc5bae-f51e-4151-8687-415c3b2e2bb9/fetchFileTemp7186468643830381162.tmp
2016-10-02 22:22:33 INFO  Executor:54 - Adding file:/private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-d80d605f-c87c-4d57-a991-27794844b0da/userFiles-22fc5bae-f51e-4151-8687-415c3b2e2bb9/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-02 22:22:33 INFO  NewHadoopRDD:54 - Input split: file:/Users/swaroopakkineni/Desktop/Fall Semester 2016/Scalable ML/project1/1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz:0+95523
2016-10-02 22:22:33 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:22:33 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:22:33 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:22:33 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:22:33 INFO  FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2016-10-02 22:22:33 INFO  CodecPool:153 - Got brand-new compressor [.gz]
2016-10-02 22:22:39 INFO  FileOutputCommitter:482 - Saved output of task 'attempt_201610022222_0003_r_000000_0' to file:/Users/swaroopakkineni/Desktop/Fall Semester 2016/Scalable ML/project1/small.adam/_temporary/0/task_201610022222_0003_r_000000
2016-10-02 22:22:39 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1115 bytes result sent to driver
2016-10-02 22:22:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 6749 ms on localhost (1/1)
2016-10-02 22:22:39 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-02 22:22:39 INFO  DAGScheduler:54 - ResultStage 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130) finished in 6.762 s
2016-10-02 22:22:39 INFO  DAGScheduler:54 - Job 0 finished: saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130, took 6.839559 s
2016-10-02 22:22:39 INFO  Vcf2ADAM:44 - Overall Duration: 9.05 secs
2016-10-02 22:22:39 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:22:39 INFO  ServerConnector:306 - Stopped ServerConnector@460f76a6{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:22:39 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4040
2016-10-02 22:22:39 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:22:39 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:22:39 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:22:39 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:22:39 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:22:39 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:22:39 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:22:39 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-d80d605f-c87c-4d57-a991-27794844b0da
2016-10-02 22:23:05 INFO  ADAMMain:115 - ADAM invoked with args: "vcf2adam" "1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz" "medium.adam"
2016-10-02 22:23:05 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-02 22:23:05 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:23:06 INFO  SecurityManager:54 - Changing view acls to: swaroopakkineni
2016-10-02 22:23:06 INFO  SecurityManager:54 - Changing modify acls to: swaroopakkineni
2016-10-02 22:23:06 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-02 22:23:06 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-02 22:23:06 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(swaroopakkineni); groups with view permissions: Set(); users  with modify permissions: Set(swaroopakkineni); groups with modify permissions: Set()
2016-10-02 22:23:06 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63126.
2016-10-02 22:23:06 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-02 22:23:06 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-02 22:23:06 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/blockmgr-37fef139-84bb-4951-9d8a-818a05c7e44b
2016-10-02 22:23:06 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-02 22:23:06 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-02 22:23:06 INFO  log:186 - Logging initialized @1346ms
2016-10-02 22:23:06 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@65e61854{/jobs,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3af17be2{/stages,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@10c8f62{/executors,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5fb97279{/,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@439a8f59{/api,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,AVAILABLE}
2016-10-02 22:23:06 INFO  ServerConnector:266 - Started ServerConnector@460f76a6{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:23:06 INFO  Server:379 - Started @1440ms
2016-10-02 22:23:06 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-02 22:23:06 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.0.3:4040
2016-10-02 22:23:06 INFO  SparkContext:54 - Added JAR file:/Users/swaroopakkineni/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://10.0.0.3:63126/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461386578
2016-10-02 22:23:06 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-02 22:23:06 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63127.
2016-10-02 22:23:06 INFO  NettyBlockTransferService:54 - Server created on 10.0.0.3:63127
2016-10-02 22:23:06 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.0.3, 63127)
2016-10-02 22:23:06 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.3:63127 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.3, 63127)
2016-10-02 22:23:06 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.0.3, 63127)
2016-10-02 22:23:06 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@78d39a69{/metrics/json,null,AVAILABLE}
2016-10-02 22:23:07 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 269.0 KB, free 366.0 MB)
2016-10-02 22:23:07 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
2016-10-02 22:23:07 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.3:63127 (size: 22.9 KB, free: 366.3 MB)
2016-10-02 22:23:07 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:795
2016-10-02 22:23:07 INFO  GenotypeRDD:114 - Saving data in ADAM format
2016-10-02 22:23:07 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-02 22:23:07 INFO  FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2016-10-02 22:23:07 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-02 22:23:07 INFO  SparkContext:54 - Starting job: saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130
2016-10-02 22:23:07 INFO  DAGScheduler:54 - Got job 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130) with 1 output partitions
2016-10-02 22:23:07 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130)
2016-10-02 22:23:07 INFO  DAGScheduler:54 - Parents of final stage: List()
2016-10-02 22:23:07 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-02 22:23:07 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at map at ADAMRDDFunctions.scala:128), which has no missing parents
2016-10-02 22:23:07 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 90.6 KB, free 365.9 MB)
2016-10-02 22:23:07 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.0 KB, free 365.9 MB)
2016-10-02 22:23:07 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.0.3:63127 (size: 34.0 KB, free: 366.2 MB)
2016-10-02 22:23:07 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-02 22:23:07 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at ADAMRDDFunctions.scala:128)
2016-10-02 22:23:07 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-02 22:23:07 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5629 bytes)
2016-10-02 22:23:07 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-02 22:23:07 INFO  Executor:54 - Fetching spark://10.0.0.3:63126/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1475461386578
2016-10-02 22:23:07 INFO  TransportClientFactory:250 - Successfully created connection to /10.0.0.3:63126 after 21 ms (0 ms spent in bootstraps)
2016-10-02 22:23:07 INFO  Utils:54 - Fetching spark://10.0.0.3:63126/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-4b9e98f7-43f0-4ed3-863b-79d27813d218/userFiles-fe2ead81-cd60-4d7c-833c-f06f932f7e8a/fetchFileTemp368973633929282900.tmp
2016-10-02 22:23:08 INFO  Executor:54 - Adding file:/private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-4b9e98f7-43f0-4ed3-863b-79d27813d218/userFiles-fe2ead81-cd60-4d7c-833c-f06f932f7e8a/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-02 22:23:08 INFO  NewHadoopRDD:54 - Input split: file:/Users/swaroopakkineni/Desktop/Fall Semester 2016/Scalable ML/project1/1.10000-80000.ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz:0+95523
2016-10-02 22:23:08 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:23:08 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:23:08 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:23:08 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-02 22:23:08 INFO  FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2016-10-02 22:23:08 INFO  CodecPool:153 - Got brand-new compressor [.gz]
2016-10-02 22:23:14 INFO  FileOutputCommitter:482 - Saved output of task 'attempt_201610022223_0003_r_000000_0' to file:/Users/swaroopakkineni/Desktop/Fall Semester 2016/Scalable ML/project1/medium.adam/_temporary/0/task_201610022223_0003_r_000000
2016-10-02 22:23:14 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1115 bytes result sent to driver
2016-10-02 22:23:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 6558 ms on localhost (1/1)
2016-10-02 22:23:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-02 22:23:14 INFO  DAGScheduler:54 - ResultStage 0 (saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130) finished in 6.573 s
2016-10-02 22:23:14 INFO  DAGScheduler:54 - Job 0 finished: saveAsNewAPIHadoopFile at ADAMRDDFunctions.scala:130, took 6.653072 s
2016-10-02 22:23:14 INFO  Vcf2ADAM:44 - Overall Duration: 8.79 secs
2016-10-02 22:23:14 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-02 22:23:14 INFO  ServerConnector:306 - Stopped ServerConnector@460f76a6{HTTP/1.1}{0.0.0.0:4040}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@61861a29{/stages/stage/kill,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@439a8f59{/api,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5fb97279{/,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5ab14cb9{/static,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3f23a3a0{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@25f7391e{/executors/threadDump,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@674c583e{/executors/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@10c8f62{/executors,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5c48c0c0{/environment/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1d9bec4d{/environment,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@362a019c{/storage/rdd/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ef27d66{/storage/rdd,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@303e3593{/storage/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5d5d9e5{/storage,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@224b4d61{/stages/pool/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6e521c1e{/stages/pool,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5f4d427e{/stages/stage/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@37f21974{/stages/stage,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@f9879ac{/stages/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3af17be2{/stages,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6f80fafe{/jobs/job/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4fcee388{/jobs/job,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1568159{/jobs/json,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@65e61854{/jobs,null,UNAVAILABLE}
2016-10-02 22:23:14 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.0.3:4040
2016-10-02 22:23:14 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-02 22:23:14 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-02 22:23:14 INFO  BlockManager:54 - BlockManager stopped
2016-10-02 22:23:14 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-02 22:23:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-02 22:23:14 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-02 22:23:14 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-02 22:23:14 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-4b9e98f7-43f0-4ed3-863b-79d27813d218
2016-10-02 22:24:29 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-02 22:24:30 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-03 14:14:01 WARN  HeartbeatReceiver:66 - Removing executor driver with no recent heartbeats: 676664 ms exceeds timeout 120000 ms
2016-10-03 14:14:01 ERROR TaskSchedulerImpl:70 - Lost executor driver on localhost: Executor heartbeat timed out after 676664 ms
2016-10-03 14:14:01 WARN  SparkContext:66 - Killing executors is only supported in coarse-grained mode
2016-10-03 21:48:39 INFO  ADAMMain:115 - ADAM invoked with args: 
2016-10-03 21:48:50 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-03 21:48:52 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-03 22:44:04 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-03 22:44:05 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 16:09:31 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 16:09:32 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 16:59:23 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@3d9b714d)
2016-10-05 16:59:23 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(18,1475701163274,JobFailed(org.apache.spark.SparkException: Job 18 cancelled because SparkContext was shut down))
2016-10-05 16:59:44 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-68993eec-2bfc-48ec-8c76-5d528c77ecfa
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-68993eec-2bfc-48ec-8c76-5d528c77ecfa
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-05 17:01:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 17:01:12 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 17:04:36 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:04:45 ERROR Executor:91 - Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:448)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:229)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)
	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:547)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:04:45 ERROR SparkUncaughtExceptionHandler:91 - Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:448)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:229)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)
	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:547)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:04:45 WARN  TaskSetManager:66 - Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:448)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:229)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)
	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:547)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-05 17:05:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 17:05:20 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 17:05:29 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:05:29 WARN  TaskSetManager:66 - Lost task 0.0 in stage 0.0 (TID 0, localhost): TaskKilled (killed intentionally)
2016-10-05 17:06:06 ERROR Executor:91 - Exception in task 0.0 in stage 3.0 (TID 2)
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:234)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:49)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:47)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:47)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1253)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:47)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:329)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:06:06 ERROR SparkUncaughtExceptionHandler:91 - Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:234)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:49)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:47)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:47)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1253)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:47)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:329)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:06:06 WARN  TaskSetManager:66 - Lost task 0.0 in stage 3.0 (TID 2, localhost): java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:234)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:49)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:47)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:47)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1253)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:47)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:329)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-05 17:06:06 ERROR TaskSetManager:70 - Task 0 in stage 3.0 failed 1 times; aborting job
2016-10-05 17:06:06 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-0c7ca734-6be3-4f7f-8379-a0776c1d4002/repl-d80431ba-4b75-4109-8058-530034faac14
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-0c7ca734-6be3-4f7f-8379-a0776c1d4002/repl-d80431ba-4b75-4109-8058-530034faac14
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-05 17:12:12 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 17:12:12 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 17:15:45 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:15:52 WARN  TaskSetManager:66 - Lost task 0.0 in stage 1.0 (TID 1, localhost): TaskKilled (killed intentionally)
2016-10-05 17:16:07 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:16:07 WARN  TaskMemoryManager:381 - leak 37.2 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@5c74f11
2016-10-05 17:16:07 WARN  TaskSetManager:66 - Lost task 0.0 in stage 4.0 (TID 3, localhost): TaskKilled (killed intentionally)
2016-10-05 17:16:19 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:16:26 WARN  TaskSetManager:66 - Lost task 0.0 in stage 5.0 (TID 4, localhost): TaskKilled (killed intentionally)
2016-10-05 17:20:29 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 17:20:30 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 17:21:30 ERROR Executor:91 - Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.ArrayIndexOutOfBoundsException: 16777215
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65)
	at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:21:30 WARN  TaskSetManager:66 - Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.ArrayIndexOutOfBoundsException: 16777215
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65)
	at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-05 17:21:30 ERROR TaskSetManager:70 - Task 0 in stage 1.0 failed 1 times; aborting job
2016-10-05 17:22:38 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@5e5fe3eb)
2016-10-05 17:22:38 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(1,1475702558918,JobFailed(org.apache.spark.SparkException: Job 1 cancelled because SparkContext was shut down))
2016-10-05 17:22:38 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-f98028c6-0495-4a23-9ee4-78e05b8ebc90
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-f98028c6-0495-4a23-9ee4-78e05b8ebc90
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-05 17:22:57 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 17:22:58 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 17:23:18 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:23:22 WARN  TaskSetManager:66 - Lost task 0.0 in stage 0.0 (TID 0, localhost): TaskKilled (killed intentionally)
2016-10-05 17:23:46 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:23:46 WARN  TaskSetManager:66 - Lost task 0.0 in stage 2.0 (TID 1, localhost): TaskKilled (killed intentionally)
2016-10-05 17:25:56 ERROR Executor:91 - Exception in task 0.0 in stage 5.0 (TID 3)
java.lang.ArrayIndexOutOfBoundsException: 16777215
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65)
	at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:25:56 WARN  TaskSetManager:66 - Lost task 0.0 in stage 5.0 (TID 3, localhost): java.lang.ArrayIndexOutOfBoundsException: 16777215
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65)
	at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-05 17:25:56 ERROR TaskSetManager:70 - Task 0 in stage 5.0 failed 1 times; aborting job
2016-10-05 17:38:11 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:38:39 WARN  TaskSetManager:66 - Lost task 0.0 in stage 13.0 (TID 10, localhost): TaskKilled (killed intentionally)
2016-10-05 17:46:01 ERROR Executor:91 - Exception in task 0.0 in stage 15.0 (TID 12)
java.lang.ArrayIndexOutOfBoundsException
2016-10-05 17:46:01 WARN  TaskSetManager:66 - Lost task 0.0 in stage 15.0 (TID 12, localhost): java.lang.ArrayIndexOutOfBoundsException

2016-10-05 17:46:01 ERROR TaskSetManager:70 - Task 0 in stage 15.0 failed 1 times; aborting job
2016-10-05 17:47:59 ERROR Executor:91 - Exception in task 0.0 in stage 19.0 (TID 15)
java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.io.Output.require(Output.java:168)
	at com.esotericsoftware.kryo.io.Output.writeVarInt(Output.java:279)
	at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:94)
	at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:517)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:619)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:47:59 WARN  TaskSetManager:66 - Lost task 0.0 in stage 19.0 (TID 15, localhost): java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.io.Output.require(Output.java:168)
	at com.esotericsoftware.kryo.io.Output.writeVarInt(Output.java:279)
	at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:94)
	at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:517)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:619)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-05 17:47:59 ERROR SparkUncaughtExceptionHandler:91 - Uncaught exception in thread Thread[Executor task launch worker-6,5,main]
java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.io.Output.require(Output.java:168)
	at com.esotericsoftware.kryo.io.Output.writeVarInt(Output.java:279)
	at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:94)
	at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:517)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:619)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:47:59 ERROR TaskSetManager:70 - Task 0 in stage 19.0 failed 1 times; aborting job
2016-10-05 17:48:00 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-f7bbb738-879b-46bf-a29b-b90ebb4b2553/repl-743727c2-4106-4b8b-9a13-1f91588bbb68
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-f7bbb738-879b-46bf-a29b-b90ebb4b2553/repl-743727c2-4106-4b8b-9a13-1f91588bbb68
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-05 17:48:43 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 17:48:44 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 17:50:19 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:50:19 WARN  TaskSetManager:66 - Lost task 0.0 in stage 0.0 (TID 0, localhost): TaskKilled (killed intentionally)
2016-10-05 17:53:31 ERROR Executor:91 - Exception in task 0.0 in stage 3.0 (TID 2)
java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:448)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:117)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)
	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:547)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:53:31 ERROR SparkUncaughtExceptionHandler:91 - Uncaught exception in thread Thread[Executor task launch worker-1,5,main]
java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:448)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:117)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)
	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:547)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 17:53:31 WARN  TaskSetManager:66 - Lost task 0.0 in stage 3.0 (TID 2, localhost): java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:448)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:117)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)
	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:547)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:82)
	at com.twitter.chill.Tuple5Serializer.write(TupleSerializers.scala:75)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-05 17:53:31 ERROR TaskSetManager:70 - Task 0 in stage 3.0 failed 1 times; aborting job
2016-10-05 17:53:32 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-f6aa5390-7263-455f-b513-2e3c0c5cbf6a
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-f6aa5390-7263-455f-b513-2e3c0c5cbf6a
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-05 17:53:44 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 17:53:44 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 17:55:32 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 17:55:32 WARN  TaskSetManager:66 - Lost task 0.0 in stage 0.0 (TID 0, localhost): TaskKilled (killed intentionally)
2016-10-05 18:04:53 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 18:04:54 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 18:05:45 ERROR Executor:91 - Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.io.Output.require(Output.java:168)
	at com.esotericsoftware.kryo.io.Output.writeVarInt(Output.java:284)
	at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:102)
	at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:517)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:622)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 18:05:45 ERROR SparkUncaughtExceptionHandler:91 - Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.io.Output.require(Output.java:168)
	at com.esotericsoftware.kryo.io.Output.writeVarInt(Output.java:284)
	at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:102)
	at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:517)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:622)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-05 18:05:45 WARN  TaskSetManager:66 - Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.io.Output.require(Output.java:168)
	at com.esotericsoftware.kryo.io.Output.writeVarInt(Output.java:284)
	at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:102)
	at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:517)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:622)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:36)
	at com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-05 18:05:45 ERROR TaskSetManager:70 - Task 0 in stage 1.0 failed 1 times; aborting job
2016-10-05 18:05:45 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-7f37ce15-df07-4900-9dd5-65556287c44e/repl-586d1552-1d04-4568-82a7-c0048d621502
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-7f37ce15-df07-4900-9dd5-65556287c44e/repl-586d1552-1d04-4568-82a7-c0048d621502
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-05 18:07:01 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 18:07:02 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-05 18:07:15 WARN  Signaling:66 - Cancelling all active jobs, this can take a while. Press Ctrl+C again to exit now.
2016-10-05 18:07:19 WARN  TaskSetManager:66 - Lost task 0.0 in stage 0.0 (TID 0, localhost): TaskKilled (killed intentionally)
2016-10-05 18:09:26 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-05 18:09:27 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-07 23:25:24 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-07 23:25:26 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-08 15:53:32 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@39ab55a0)
2016-10-08 15:53:32 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1475956412117,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
2016-10-08 15:53:32 ERROR Executor:91 - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NullPointerException
	at org.apache.spark.SparkFiles$.getRootDirectory(SparkFiles.scala:37)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:488)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:480)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$updateDependencies(Executor.scala:480)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:252)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-08 15:53:32 ERROR Executor:91 - Exception in task 1.0 in stage 0.0 (TID 1)
java.io.IOException: Failed to connect to /10.0.0.3:61989
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:358)
	at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:324)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:633)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:459)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:488)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:480)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$updateDependencies(Executor.scala:480)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:252)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.channels.ClosedChannelException
2016-10-08 15:53:32 WARN  NettyRpcEnv:66 - RpcEnv already stopped.
2016-10-08 15:53:32 WARN  NettyRpcEnv:66 - RpcEnv already stopped.
2016-10-08 15:53:32 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-6d1cf234-9bee-4937-895f-4a14a04560c1/repl-cb147154-f7dd-4098-8f4a-97767a5bb2e9
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-6d1cf234-9bee-4937-895f-4a14a04560c1/repl-cb147154-f7dd-4098-8f4a-97767a5bb2e9
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-08 15:53:52 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-08 15:53:53 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-08 17:23:06 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-4a7fc401-f3d8-4337-a5d8-88ecb8c2535f
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-4a7fc401-f3d8-4337-a5d8-88ecb8c2535f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-08 17:23:06 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-4a7fc401-f3d8-4337-a5d8-88ecb8c2535f/repl-926d99d0-18b6-4a6f-a996-413e8598b2c4
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-4a7fc401-f3d8-4337-a5d8-88ecb8c2535f/repl-926d99d0-18b6-4a6f-a996-413e8598b2c4
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-08 17:23:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-08 17:23:20 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-08 19:06:23 WARN  HeartbeatReceiver:66 - Removing executor driver with no recent heartbeats: 1007505 ms exceeds timeout 120000 ms
2016-10-08 19:06:23 ERROR TaskSchedulerImpl:70 - Lost executor driver on localhost: Executor heartbeat timed out after 1007505 ms
2016-10-08 19:06:23 WARN  SparkContext:66 - Killing executors is only supported in coarse-grained mode
2016-10-08 20:11:06 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@74e0ed5f)
2016-10-08 20:11:06 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(107,1475971866432,JobFailed(org.apache.spark.SparkException: Job 107 cancelled because SparkContext was shut down))
2016-10-08 20:11:08 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.lang.IllegalStateException: Block broadcast_285 not found
	at org.apache.spark.storage.BlockInfoManager$$anonfun$1.apply(BlockInfoManager.scala:288)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$1.apply(BlockInfoManager.scala:288)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:287)
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:628)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:123)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:97)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:95)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:95)
	at org.apache.spark.scheduler.Task.run(Task.scala:98)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-08 20:11:08 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.lang.IllegalStateException: Block broadcast_286 not found
	at org.apache.spark.storage.BlockInfoManager$$anonfun$1.apply(BlockInfoManager.scala:288)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$1.apply(BlockInfoManager.scala:288)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:287)
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:628)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:123)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:97)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:95)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:95)
	at org.apache.spark.scheduler.Task.run(Task.scala:98)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-08 20:11:08 ERROR Executor:91 - Exception in task 0.0 in stage 178.0 (TID 286)
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:347)
	at scala.None$.get(Option.scala:345)
	at org.apache.spark.storage.BlockInfoManager.releaseAllLocksForTask(BlockInfoManager.scala:343)
	at org.apache.spark.storage.BlockManager.releaseAllLocksForTask(BlockManager.scala:644)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:281)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-08 20:11:11 WARN  NettyRpcEnv:66 - RpcEnv already stopped.
2016-10-08 20:11:55 ERROR ShutdownHookManager:91 - Exception while deleting Spark temp dir: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-7ffe2bc5-c293-4f95-91f8-8e6ef26e0f01/repl-f23f360a-4b98-463e-b797-5225718a9639
java.io.IOException: Failed to delete: /private/var/folders/cb/vh6yg1815r3_jcrl436482ww0000gn/T/spark-7ffe2bc5-c293-4f95-91f8-8e6ef26e0f01/repl-f23f360a-4b98-463e-b797-5225718a9639
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:986)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:64)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:61)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:61)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2016-10-08 20:26:52 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-08 20:26:53 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-08 21:46:47 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-08 21:46:48 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-08 21:47:25 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(driver,WrappedArray((119,74,0,Vector(AccumulableInfo(4246,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(4247,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(4248,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(4249,Some(internal.metrics.jvmGCTime),Some(159739),None,true,true,None), AccumulableInfo(4250,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(4251,Some(internal.metrics.memoryBytesSpilled),Some(384984361),None,true,true,None), AccumulableInfo(4252,Some(internal.metrics.diskBytesSpilled),Some(18098056),None,true,true,None), AccumulableInfo(4253,Some(internal.metrics.peakExecutionMemory),Some(384984361),None,true,true,None), AccumulableInfo(4254,Some(internal.metrics.updatedBlockStatuses),Some(ArrayBuffer()),None,true,true,None), AccumulableInfo(4255,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(4256,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(1),None,true,true,None), AccumulableInfo(4257,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(4258,Some(internal.metrics.shuffle.read.localBytesRead),Some(18381710),None,true,true,None), AccumulableInfo(4259,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(4260,Some(internal.metrics.shuffle.read.recordsRead),Some(1384423),None,true,true,None), AccumulableInfo(4261,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(4262,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(4263,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(4264,Some(internal.metrics.input.bytesRead),Some(0),None,true,true,None), AccumulableInfo(4265,Some(internal.metrics.input.recordsRead),Some(0),None,true,true,None), AccumulableInfo(4266,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(4267,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None)))))
2016-10-08 21:47:29 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@51de6c94)
2016-10-08 21:47:35 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(driver,WrappedArray((119,74,0,Vector(AccumulableInfo(4246,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(4247,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(4248,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(4249,Some(internal.metrics.jvmGCTime),Some(168173),None,true,true,None), AccumulableInfo(4250,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(4251,Some(internal.metrics.memoryBytesSpilled),Some(384984361),None,true,true,None), AccumulableInfo(4252,Some(internal.metrics.diskBytesSpilled),Some(18098056),None,true,true,None), AccumulableInfo(4253,Some(internal.metrics.peakExecutionMemory),Some(384984361),None,true,true,None), AccumulableInfo(4254,Some(internal.metrics.updatedBlockStatuses),Some(ArrayBuffer()),None,true,true,None), AccumulableInfo(4255,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(4256,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(1),None,true,true,None), AccumulableInfo(4257,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(4258,Some(internal.metrics.shuffle.read.localBytesRead),Some(18381710),None,true,true,None), AccumulableInfo(4259,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(4260,Some(internal.metrics.shuffle.read.recordsRead),Some(1384423),None,true,true,None), AccumulableInfo(4261,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(4262,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(4263,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(4264,Some(internal.metrics.input.bytesRead),Some(0),None,true,true,None), AccumulableInfo(4265,Some(internal.metrics.input.recordsRead),Some(0),None,true,true,None), AccumulableInfo(4266,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(4267,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None)))))
2016-10-08 21:47:41 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(44,1475977655739,JobFailed(org.apache.spark.SparkException: Job 44 cancelled because SparkContext was shut down))
2016-10-08 21:47:44 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(driver,WrappedArray((119,74,0,Vector(AccumulableInfo(4246,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(4247,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(4248,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(4249,Some(internal.metrics.jvmGCTime),Some(179711),None,true,true,None), AccumulableInfo(4250,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(4251,Some(internal.metrics.memoryBytesSpilled),Some(384984361),None,true,true,None), AccumulableInfo(4252,Some(internal.metrics.diskBytesSpilled),Some(18098056),None,true,true,None), AccumulableInfo(4253,Some(internal.metrics.peakExecutionMemory),Some(384984361),None,true,true,None), AccumulableInfo(4254,Some(internal.metrics.updatedBlockStatuses),Some(ArrayBuffer()),None,true,true,None), AccumulableInfo(4255,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(4256,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(1),None,true,true,None), AccumulableInfo(4257,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(4258,Some(internal.metrics.shuffle.read.localBytesRead),Some(18381710),None,true,true,None), AccumulableInfo(4259,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(4260,Some(internal.metrics.shuffle.read.recordsRead),Some(1384423),None,true,true,None), AccumulableInfo(4261,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(4262,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(4263,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(4264,Some(internal.metrics.input.bytesRead),Some(0),None,true,true,None), AccumulableInfo(4265,Some(internal.metrics.input.recordsRead),Some(0),None,true,true,None), AccumulableInfo(4266,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(4267,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None)))))
2016-10-08 21:47:57 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(driver,WrappedArray((119,74,0,Vector(AccumulableInfo(4246,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(4247,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(4248,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(4249,Some(internal.metrics.jvmGCTime),Some(189489),None,true,true,None), AccumulableInfo(4250,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(4251,Some(internal.metrics.memoryBytesSpilled),Some(384984361),None,true,true,None), AccumulableInfo(4252,Some(internal.metrics.diskBytesSpilled),Some(18098056),None,true,true,None), AccumulableInfo(4253,Some(internal.metrics.peakExecutionMemory),Some(384984361),None,true,true,None), AccumulableInfo(4254,Some(internal.metrics.updatedBlockStatuses),Some(ArrayBuffer()),None,true,true,None), AccumulableInfo(4255,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(4256,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(1),None,true,true,None), AccumulableInfo(4257,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(4258,Some(internal.metrics.shuffle.read.localBytesRead),Some(18381710),None,true,true,None), AccumulableInfo(4259,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(4260,Some(internal.metrics.shuffle.read.recordsRead),Some(1384423),None,true,true,None), AccumulableInfo(4261,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(4262,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(4263,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(4264,Some(internal.metrics.input.bytesRead),Some(0),None,true,true,None), AccumulableInfo(4265,Some(internal.metrics.input.recordsRead),Some(0),None,true,true,None), AccumulableInfo(4266,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(4267,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None)))))
2016-10-08 21:48:21 ERROR Utils:91 - Uncaught exception in thread driver-heartbeater
java.lang.OutOfMemoryError: GC overhead limit exceeded
2016-10-08 21:48:28 WARN  TaskMemoryManager:381 - leak 5.0 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@1f1c908f
2016-10-08 21:48:28 ERROR Executor:91 - Exception in task 0.0 in stage 74.0 (TID 119)
java.lang.OutOfMemoryError: GC overhead limit exceeded
2016-10-08 21:48:28 ERROR SparkUncaughtExceptionHandler:91 - [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-11,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
2016-10-08 21:50:50 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-08 21:50:51 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
